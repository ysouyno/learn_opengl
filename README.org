#+options: ':nil *:t -:t ::t <:t H:3 \n:nil ^:nil arch:headline
#+options: author:t broken-links:nil c:nil creator:nil
#+options: d:(not "LOGBOOK") date:t e:t email:nil f:t inline:t num:t
#+options: p:nil pri:nil prop:nil stat:t tags:t tasks:t tex:t
#+options: timestamp:t title:t toc:t todo:t |:t
#+title: learn_opengl
#+date: <2024-09-27 周五>
#+author: ysouyno
#+email:
#+language: en
#+select_tags: export
#+exclude_tags: noexport
#+creator: Emacs 29.4 (Org mode 9.6.15)
#+cite_export:

* <2024-09-29 周日> 前言

教程链接：“[[https://learnopengl-cn.github.io/][LearnOpenGL CN]]”。

* <2021-12-05 周日> 环境配置（ ~linux~ ）

** ~archlinux~ 环境配置

分别用到了 ~glfw~ ， ~stb~ ， ~glm~ 和 ~glad~ ，其中 ~glfw~ 和 ~stb~ 直接从 ~github~ 上克隆最新代码：

#+begin_src shellsession
$ git clone https://github.com/glfw/glfw.git
$ git clone https://github.com/nothings/stb.git
#+end_src

其中 ~glfw~ 需要编译一下才能使用，很简单：

#+begin_src shellsession
$ cd glfw
$ mkdir build
$ cd build
$ cmake ..
$ make
#+end_src

~glm~ 是按照教程中的建议，选择了低于 ~0.9.9~ 的版本，下载地址：“[[https://github.com/g-truc/glm/releases/tag/0.9.8.5][GLM 0.9.8.5]]”。

~glad~ 用的好像是教程中提供的在线服务链接生成的“[[https://glad.dav1d.de][Glad]]”，另项目中的 ~glad.c~ 是指向本机电脑中的一个软链接。

** 编译

编译及链接选项参考项目的 ~.vscode~ 中的文件。另因为使用 ~clang-format~ 格式化代码，头文件的顺序会影响编译，所以我在 ~~/.clang-format~ 中关闭了这项功能。

#+begin_src shellsession
$ cat ~/.clang-format
Language: Cpp
SortIncludes: false
#+end_src

* <2024-09-27 周五> 环境配置（ ~windows~ ）

** ~vs2010~

1. 创建 ~solution~ 文件 ~learn_opengl.sln~ 。
2. 创建 ~third_party~ 目录。
3. 下载预编译好的“[[https://github.com/glfw/glfw/releases/download/3.3.5/glfw-3.3.5.bin.WIN32.zip][glfw-3.3.5.bin.WIN32.zip]]”。

** ~assimp~

想在 ~vs2010~ 上自己编译 ~assimp~ 的，发现 ~cmake~ 自 ~3.25~ 版本已经移除了 ~vs2010~ ，所以我选择了 ~cmake-3.24.4~ 版本。其实不算什么，只是提醒一下以节省时间。

这个库很难编译，或者说非常麻烦。我在这里“[[https://sourceforge.net/projects/assimp/files/assimp-3.1/][assimp-3.1.1-win-binaries.zip]]”找到了一个预编译二进制包下载，但是好像不能运行。居然提示，一个 ~exe~ 的运行依赖另一个 ~exe~ ，开眼了。

#+ATTR_HTML: :width 60%
[[file:files/20240929_0.png]]

目前的进展是，直接双击 ~assimp.exe~ 会提示缺少 ~msvcr110.dll~ 和 ~msvcp110.dll~ ，这两个文件我在网上下载的出现各种问题，最后安装了 ~vcredist_x86.exe~ （即 ~Microsoft Visual C++ 2012 Redistributable (x86)~ ）解决的，虽然 ~assimp.exe~ 成功运行了，但是上面的错误提示框依然存在。所以我只能选择 ~vs2022~ 来编译。因为其实这个库在 ~vs2022~ 上编译非常方便，在 ~cmake-3.24.4~ 上不用任何配置就编译成功了。

#+ATTR_HTML: :width 60%
[[file:files/20240929_1.png]]

我用的是当前最新的版本 ~assimp-5.4.3~ ，运行效果如下：

#+ATTR_HTML: :width 60%
[[file:files/20240929_2.png]]

*** ~assimp-3.1.1~

尝试自己在 ~vs2010~ 上编译 [[https://sourceforge.net/projects/assimp/files/assimp-3.1/][assimp-3.1.1]] ，首先需要安装：

+ ~GoRuntime_DotNetFramework_3.x.exe~
+ ~DXSDK_Jun10.exe~ （ ~win10~ 系统上它依赖于 ~DotNetFramework_3.5~ ）
+ [[https://cmake.org/files/v2.8/cmake-2.8.6-win32-x86.exe][cmake-2.8.6-win32-x86.exe]]

#+ATTR_HTML: :width 60%
[[file:files/20240929_3.png]]

在安装 ~GoRuntime_DotNetFramework_3.x.exe~ 时发生 ~Error Code: S1023~

+ 尝试卸载 ~Microsoft Visual C++ 2010 x86 Redistributable - 1010.0.40219~ ，失败。
+ 尝试卸载 ~Microsoft Visual C++ 2012 Redistributable (x86)~ ，失败。
+ 尝试卸载 ~Microsoft Visual C++ 2010 x64 Redistributable - 1010.0.40219~ ，成功。

这样 ~cmake-2.8.6~ 也运行成功了，附上我的 ~csdn~ 资源：“[[https://download.csdn.net/download/ftuc5dn/89815337][assimp-3.1.1 预编译二进制文件（32位）]]”。

#+ATTR_HTML: :width 60%
[[file:files/20240929_4.png]]

~vs2010~ 成功：

#+ATTR_HTML: :width 60%
[[file:files/20240929_5.png]]

* <2021-12-06 周一> 入门.坐标系统

在“坐标系统”的“更多立方体”中提供的代码，文章中提到这十个立方体都能自主旋转，其实不然。我稍微修改了他的代码实现了，见：“[[https://github.com/ysouyno/learn_opengl/commit/b49247b5f9e1dd5e5b92809fe2235b948185767a][more cubes]]”，主要是这两处修改：

#+begin_src c++
  float angle = 20.0f * (i + 1);
  model = glm::rotate(model, (float)glfwGetTime() * glm::radians(angle),
                      glm::vec3(1.0f, 0.3f, 0.5f));
#+end_src

原代码中 ~angle = 20.0f * i~ 会导致最中间的那个立方体不旋转。

* <2024-09-27 周五> 光照.基础光照

背后的数学知道可能需要回顾，代码中的注释说明了一切：

#+begin_src glsl
  #version 330 core
  out vec4 FragColor;

  in vec3 Normal;
  in vec3 FragPos;

  uniform vec3 objectColor;
  uniform vec3 lightColor;
  uniform vec3 lightPos;

  void main()
  {
    // amibent
    float ambientStrength = 0.1;
    vec3 ambient = ambientStrength * lightColor;

    // diffuse
    // 因为只关心方向向量的方向，所以这里先进行标准化，即 normalize
    // norm 是书中所说的法向量，垂直于立面体表面
    vec3 norm = normalize(Normal);
    vec3 lightDir = normalize(lightPos - FragPos);

    // 将法向量和方向向量进行点乘，会得到它们之前夹角的余弦值
    float diff = max(dot(norm, lightDir), 0.0);
    vec3 diffuse = diff * lightColor;

    vec3 result = (ambient + diffuse) * objectColor;
    FragColor = vec4(result, 1.0);
  }
#+end_src

* <2024-09-27 周五> 光照.材质.设置材质

我按照教程一步一步来操作，但没有得到相同的效果：

#+ATTR_HTML: :width 50%
[[file:files/20240927_0.png]]

#+ATTR_HTML: :width 50%
[[file:files/20240927_1.png]]

原来在设置 ~material.shininess~ 时变量名拼写错误了，看评论说 ~shininess~ 设置为 ~0~ 时会出现黑色。

* <2024-09-28 周六> 光照.光照贴图.练习

练习的最后一题没有提供答案，我的答案是（上图是参考答案，下图是我的答案）：

#+ATTR_HTML: :width 50%
[[file:files/20240928_0.png]]

#+ATTR_HTML: :width 50%
[[file:files/20240928_1.png]]

我是这么修改代码的：

#+ATTR_HTML: :width 80%
[[file:files/20240928_2.png]]

* <2024-09-28 周六> 光照.投光物.平行光

当前 ~commit~ 下可以看到 ~平行光~ 的效果，但是只能显示一个立方体，且不能旋转，与书中提供的贴图效果不一样，且书中提供的代码也与贴图不一致。

看了半天也不知道问题出在哪里，那么在此代码基础上如何显示出十个立方体呢？

这个问题解决了，原来是 ~2.5.light_cube.vs~ 的问题，代码中一直在用 ~aPos~ ，它是直接来自输入参数，并没有 ~model~ 的计算处理，所以只能显示一个立方体，所以现在用 ~FragPos~ 就解决了。

* <2024-09-28 周六> 光照.复习.词汇表

这一部分的内容真的好多，需要时不时的温故一下，否则学习的时间又浪费了！两天的时间居然学习了这么多新知识：

+ 颜色向量（ ~Color Vector~ ）：一个通过红绿蓝（ ~RGB~ ）分量的组合描绘大部分真实颜色的向量。一个物体的颜色实际上是该物体所不能吸收的反射颜色分量。
+ 风氏光照模型（ ~Phong Lighting Model~ ）：一个通过计算环境光，漫反射，和镜面光分量的值来近似真实光照的模型。
+ 环境光照（ ~Ambient Lighting~ ）：通过给每个没有被光照的物体很小的亮度，使其不是完全黑暗的，从而对全局光照进行近似。
+ 漫反射着色（ ~Diffuse Shading~ ）：一个顶点/片段与光线方向越接近，光照会越强。使用了法向量来计算角度。
+ 法向量（ ~Normal Vector~ ）：一个垂直于平面的单位向量。
+ 法线矩阵（ ~Normal Matrix~ ）：一个 ~3x3~ 矩阵，或者说是没有平移的模型（或者模型-观察）矩阵。它也被以某种方式修改（逆转置），从而在应用非统一缩放时，保持法向量朝向正确的方向。否则法向量会在使用非统一缩放时被扭曲。
+ 镜面光照（ ~Specular Lighting~ ）：当观察者视线靠近光源在表面的反射线时会显示的镜面高光。镜面光照是由观察者的方向，光源的方向和设定高光分散量的反光度值三个量共同决定的。
+ 风氏着色（ ~Phong Shading~ ）：风氏光照模型应用在片段着色器。
+ ~Gouraud~ 着色（ ~Gouraud shading~ ）：风氏光照模型应用在顶点着色器上。在使用很少数量的顶点时会产生明显的瑕疵。会得到效率提升但是损失了视觉质量。
+ ~GLSL~ 结构体（ ~GLSL struct~ ）：一个类似于 ~C~ 的结构体，用作着色器变量的容器。大部分时间用来管理输入/输出/ ~uniform~ 。
+ 材质（ ~Material~ ）：一个物体反射的环境光，漫反射，镜面光颜色。这些东西设定了物体所拥有的颜色。
+ 光照属性（ ~Light~ （ ~properties~ ））：一个光的环境光，漫反射，镜面光的强度。可以使用任何颜色值，对每一个风氏分量（ ~Phong Component~ ）定义光源发出的颜色/强度。
+ 漫反射贴图（ ~Diffuse Map~ ）：一个设定了每个片段中漫反射颜色的纹理图片。
+ 镜面光贴图（ ~Specular Map~ ）：一个设定了每一个片段的镜面光强度/颜色的纹理贴图。仅在物体的特定区域显示镜面高光。
+ 定向光（ ~Directional Light~ ）：只有方向的光源。它被建模为无限距离，这使得它的所有光线看起来都是平行的，因此它的方向矢量在整个场景中保持不变。
+ 点光源（ ~Point Light~ ）：一个在场景中有位置的，光线逐渐衰减的光源。
+ 衰减（ ~Attenuation~ ）：光随着距离减少强度减小的过程，通常使用在点光源和聚光下。
+ 聚光（ ~Spotlight~ ）：一个被定义为在某一个方向上的锥形的光源。
+ 手电筒（ ~Flashlight~ ）：一个摆放在观察者视角的聚光。
+ ~GLSL Uniform~ 数组（ ~GLSL Uniform Array~ ）：一个 ~uniform~ 值数组。它的工作原理和 ~C~ 语言数组大致一样，只是不能动态分配内存。

* <2024-10-01 周二> 高级 ~OpenGL~ .模板测试.物体轮廓（一）

注意到这个变量非常重要 ~GL_STENCIL_BUFFER_BIT~ ，如果不设置它，效果非常的差，你可以试着取消它看看效果。

说实话，我真的没有看懂这一节的内容！

* <2024-10-01 周二> 高级 ~OpenGL~ .模板测试.物体轮廓（二）

关于物体轮廓的 ~stencil~ 代码流程理解：

#+begin_src c++
  // configure global opengl state
  // -----------------------------
  glEnable(GL_DEPTH_TEST);
  glDepthFunc(GL_LESS);
  glEnable(GL_STENCIL_TEST);
  glStencilFunc(GL_NOTEQUAL, 1, 0xFF);
  glStencilOp(GL_KEEP, GL_KEEP, GL_REPLACE);
#+end_src

在全局设置中，先启用 ~stencil~ 测试，并设置不为 ~1~ 时通过测试（这里似乎没什么用），这里有两个函数通俗点讲：

+ ~glStencilFunc~ 设置对缓冲区做什么，比如等于 ~1~ 时通过测试。
+ ~glStencilOp~ 设置如何更新缓冲区，比如上述代码，第一个参数表示深度测试通过但 ~stencil~ 测试失败时保留缓冲区，第二个参数表示 ~stencil~ 测试通过但深度测试失败时保留缓冲区，第三个参数表示两个测试都通过时将模板值设置为 ~glStencilFunc~ 函数设置的 ~ref~ 值。

#+begin_src c++
  // draw floor as normal, but don't write the floor to the stencil buffer,
  // we only care about the containers. We set its mask to 0x00 to not write to the stencil buffer.
  glStencilMask(0x00);
#+end_src

先绘制地板，因为地板不进模板测试缓冲区，所以设置 ~mask~ 为 ~0x00~ ，此时的模板测试缓冲区为空。

#+begin_src c++
  // 1st. render pass, draw objects as normal, writing to the stencil buffer
  // --------------------------------------------------------------------
  glStencilFunc(GL_ALWAYS, 1, 0xFF);
  glStencilMask(0xFF);
#+end_src

绘制完地板后要写入模板测试缓冲区了，所以此时将 ~mask~ 设置为 ~0xFF~ ，表示启用模板缓冲区写入。通过使用 ~GL_ALWAYS~ 模板测试函数，我们保证了箱子的每个片段都会将模板缓冲的模板值更新为 ~1~ 。

+ ~glStencilFunc(GL_ALWAYS, 1, 0xFF);~ 表示总是将模板值与参考值 ~1~ 进行比较？（对这个函数好抽象）

紧接着绘制立方体，这样立方体的数据就写入到了模板测试缓冲区里了。此时缓冲区里只有两个立方体的数据（没有地板哦），然后设置：

#+begin_src c++
  // 2nd. render pass: now draw slightly scaled versions of the objects, this time disabling stencil writing.
  // Because the stencil buffer is now filled with several 1s. The parts of the buffer that are 1 are not drawn, thus only drawing
  // the objects' size differences, making it look like borders.
  // -----------------------------------------------------------------------------------------------------------------------------
  glStencilFunc(GL_NOTEQUAL, 1, 0xFF);
  glStencilMask(0x00);
  glDisable(GL_DEPTH_TEST);
  shaderSingleColor.use();
  float scale = 1.1f;
#+end_src

这里设置不为 ~1~ 时通过模板测试，所以已经绘制的两个立方体之外的区域才可以通过模板测试，并禁止了模板缓冲区的写入。同时禁用了深度测试，它的目的是为了在绘制时边框不会被地板覆盖。

这里的伪代码表达了整个流程，非常直观：

#+begin_src c++
  glEnable(GL_DEPTH_TEST);
  glStencilOp(GL_KEEP, GL_KEEP, GL_REPLACE);

  glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT | GL_STENCIL_BUFFER_BIT);

  glStencilMask(0x00); // 记得保证我们在绘制地板的时候不会更新模板缓冲
  normalShader.use();
  DrawFloor()

  glStencilFunc(GL_ALWAYS, 1, 0xFF);
  glStencilMask(0xFF);
  DrawTwoContainers();

  glStencilFunc(GL_NOTEQUAL, 1, 0xFF);
  glStencilMask(0x00);
  glDisable(GL_DEPTH_TEST);
  shaderSingleColor.use();
  DrawTwoScaledUpContainers();
  glStencilMask(0xFF);
  glEnable(GL_DEPTH_TEST);
#+end_src

* <2024-10-09 周三> 高级 ~OpenGL~ .几何着色器

#+begin_src glsl
  void build_house(vec4 position) {
    fColor = gs_in[0].color;
    gl_Position = position + vec4(-0.2, -0.2, 0.0, 0.0);
    EmitVertex();
    gl_Position = position + vec4( 0.2, -0.2, 0.0, 0.0);
    EmitVertex();
    gl_Position = position + vec4(-0.2,  0.2, 0.0, 0.0);
    EmitVertex();
    gl_Position = position + vec4( 0.2,  0.2, 0.0, 0.0);
    EmitVertex();
    gl_Position = position + vec4( 0.0,  0.4, 0.0, 0.0);
    fColor = vec3(1.0, 1.0, 1.0); // 屋顶上的落雪效果
    EmitVertex();
    EndPrimitive();
  }
#+end_src

<<白色屋顶>>
为啥这里加上 ~fColor = vec3(1.0, 1.0, 1.0);~ 的效果是屋顶颜色渐变，以我的理解，不应该将之前 ~fColor = gs_in[0].color;~ 设置的值覆盖掉了嘛，会导致所以四个房子都变成白色的。

我以为在代码中只加载了 ~Model nanosuit("nanosuit/nanosuit.obj");~ 一个文件，那实际上也就只需要一个 ~nanosuit.obj~ 文件即可呢，但其实如果只用这一个文件的话，显示出来的将是全黑色的角色。所以我把缺失的文件都添加上了。

* <2024-10-10 周四> 高级 ~OpenGL~ .实例化.实例化数组

这行 ~glVertexAttribDivisor(2, 1);~ 代码是点睛之笔！如果没有它整个输出是错乱的。我也试着将第二个参数改为 ~2~ ，这样只显示了下半部分；改成 ~5~ 只显示底部的五分之一。

这是实例化数组，上一个 ~commit~ ，使用的是 ~uniform~ 来传递，它在 ~opengl~ 中有数量上限的限制，所以这里采用实例化数组就没有这个限制了，限制它的只有内存了。

绘制顺序将从左下角向右再向上绘制，从该绘制效果上可以看出。

* <2024-10-10 周四> 高级 ~OpenGL~ .实例化.小行星带

哇喔！效果杠杠的。但是这里并没有使用实例化，它用了一个超大的 ~modelMatrices~ 数组来存放小行星的矩阵。最终运行效果：

#+ATTR_HTML: :width 50%
[[file:files/20241010_0.png]]

使用实例化后产生十万个小行星的效果如下，对于办公室这个电脑稍微有点慢了：

#+ATTR_HTML: :width 50%
[[file:files/20241010_1.png]]

我不太理解这段代码：

#+begin_src c++
  // set transformation matrices as an instance vertex attribute (with divisor 1)
  // note: we're cheating a little by taking the, now publicly declared,
  // VAO of the model's mesh(es) and adding new vertexAttribPointers
  // normally you'd want to do this in a more organized fashion, but for learning purposes this will do
  // --------------------------------------------------------------------------------------------------
  for (unsigned int i = 0; i < rock.meshes.size(); ++i) {
    unsigned int VAO = rock.meshes[i].VAO;
    glBindVertexArray(VAO);

    // set attribute pointers for matrix (4 times vec4)
    glEnableVertexAttribArray(3);
    glVertexAttribPointer(3, 4, GL_FLOAT, GL_FALSE, sizeof(glm::mat4), (void*)0);
    glEnableVertexAttribArray(4);
    glVertexAttribPointer(4, 4, GL_FLOAT, GL_FALSE, sizeof(glm::mat4), (void*)(1 * sizeof(glm::vec4)));
    glEnableVertexAttribArray(5);
    glVertexAttribPointer(5, 4, GL_FLOAT, GL_FALSE, sizeof(glm::mat4), (void*)(2 * sizeof(glm::vec4)));
    glEnableVertexAttribArray(6);
    glVertexAttribPointer(6, 4, GL_FLOAT, GL_FALSE, sizeof(glm::mat4), (void*)(3 * sizeof(glm::vec4)));

    glVertexAttribDivisor(3, 1);
    glVertexAttribDivisor(4, 1);
    glVertexAttribDivisor(5, 1);
    glVertexAttribDivisor(6, 1);

    glBindVertexArray(0);
   }
#+end_src

为什么 ~glVertexAttribPointer~ 的第五个参数是 ~sizeof(glm::mat4)~ 而不是 ~sizeof(glm::vec4)~ 呢？

* <2024-10-10 周四> 高级 ~OpenGL~ .抗锯齿

只需要添加两行代码：

#+begin_src c++
  glfwWindowHint(GLFW_SAMPLES, 4);
  glEnable(GL_MULTISAMPLE);
#+end_src

也可以只有一句代码：

#+begin_src c++
  glfwWindowHint(GLFW_SAMPLES, 4);
#+end_src

~glfwWindowHint~ 的第二个参数表示一个像素中有几个采样点，数量越多越平滑。

* <2024-10-10 周四> 高级 ~OpenGL~ .抗锯齿.离屏 ~MSAA~ （一）

关于帧缓冲（ ~framebuffer~ ）的概念对我来说非常容易忘记，这个章节当时国庆假期在家时就反复看，但是从没入心。所以回看帧缓冲这节希望下面的知识点方便理解：

+ 一个完整的帧缓冲需要满足以下的条件：
  - 附加至少一个缓冲（颜色、深度或模板缓冲）
  - 至少有一个颜色附件（ ~Attachment~ ）
  - 所有的附件都必须是完整的（保留了内存）（申请好了足够的内存空间）
  - 每个缓冲都应该有相同的样本数（ ~sample~ ）
+ 渲染到一个不同的帧缓冲被叫做离屏渲染（ ~Off-screen Rendering~ ）。
+ 要保证所有的渲染操作在主窗口中有视觉效果，我们需要再次激活默认帧缓冲，将它绑定到 ~0~ ，即 ~glBindFramebuffer(GL_FRAMEBUFFER, 0);~ 。
+ ~附件~ 是一个内存位置，它能够作为帧缓冲的一个缓冲，可以将它想象为一个图像。当创建一个附件的时候我们有两个选项：
  - 纹理
  - 渲染缓冲对象（ ~Renderbuffer Object~ ）

有 ~颜色~ ， ~深度~ ， ~模板~ 三种附件：

#+begin_quote
由于渲染缓冲对象通常都是只写的，它们会经常用于 ~深度~ 和 ~模板~ 附件。

我们需要深度和模板值用于测试，但不需要对它们进行采样，所以渲染缓冲对象非常适合它们。当我们不需要从这些缓冲中采样的时候，通常都会选择渲染缓冲对象，因为它会更优化一点。

渲染缓冲对象能为你的帧缓冲对象提供一些优化，但知道什么时候使用渲染缓冲对象，什么时候使用纹理是很重要的。通常的规则是，如果你不需要从一个缓冲中采样数据，那么对这个缓冲使用渲染缓冲对象会是明智的选择。如果你需要从缓冲中采样颜色或深度值等数据，那么你应该选择纹理附件。性能方面它不会产生非常大的影响的。
#+end_quote

复习至此为止，最后交待一下为什么有 ~帧缓冲~ ，因为有了它可以方便的进行：
+ 反相处理（ ~Inversion~ ）
+ 灰度处理（ ~Grayscale~ ）
+ 模糊效果（ ~Blur~ ）
+ 边缘检测（ ~Edge-detection~ ）

等等等。

为了达到学习效果，现将在 ~advanced_opengl_anti_aliasing_msaa~ 工程基础上生成的 ~advanced_opengl_anti_aliasing_offscreen~ 工程改成使用帧缓冲的有锯齿的渲染效果。

* <2024-10-11 周五> 高级 ~OpenGL~ .抗锯齿.离屏 ~MSAA~ （二）

应该说我对于 ~帧缓冲~ 的理解更深入了，上节提到的将现在工程中的有锯齿效果采用帧缓冲实现一下，然后在会下一个 ~commit~ 中将有锯齿的帧缓冲变成抗锯齿的帧缓冲。

我是这么修改成帧缓冲的（我是充分研究了 ~advanced_opengl_framebuffers~ 工程的）：

1. 创建帧缓冲的操作不用说，放在循环外面实现（详见上上个 ~commit: 13c20bf5ceb2c5afa4bc79f0176ac91d97533822 (still trying)~ ）
2. 然后在循环内部先将创建的新帧缓冲绑定为当前有效，并启用深度测试，紧接着正常绘制立方体。
   + 这里为什么要启用深度测试？因为在循环结尾时为了显示 ~screen-space quad~ ，将深度测试给禁用了。
3. 然后绑定默认的帧缓冲为当前有效，再禁用深度测试。
4. 最后在循环尾部绘制 ~quad plane~ ，这样，一次循环结束。

最后的帧缓冲的有锯齿绘制效果如下：

#+ATTR_HTML: :width 80%
[[file:files/20241011_0.png]]

* <2024-10-12 周六> 高级 ~OpenGL~ .抗锯齿.离屏 ~MSAA~ （三）

这段代码的用意是啥？书中不曾讲，但是我猜可能跟我上节中实现的帧缓冲的方式不太一样导致：

#+begin_src c++
  // configure second post-processing framebuffer
  unsigned int intermediateFBO;
  glGenFramebuffers(1, &intermediateFBO);
  glBindFramebuffer(GL_FRAMEBUFFER, intermediateFBO);
  // create a color attachment texture
  unsigned int screenTexture;
  glGenTextures(1, &screenTexture);
  glBindTexture(GL_TEXTURE_2D, screenTexture);
  glTexImage2D(GL_TEXTURE_2D, 0, GL_RGB, SCR_WIDTH, SCR_HEIGHT, 0, GL_RGB, GL_UNSIGNED_BYTE, NULL);
  glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR);
  glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR);
  glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D, screenTexture, 0); // we only need a color buffer
#+end_src

~glBlitFramebuffer~ 这个函数就像 ~gdi~ 函数 ~BitBlt~ 似的进行了两个 ~DC~ 的拷贝。那 ~intermediateFBO~ 似乎就像它的名字中的 ~intermediate~ 一样，就是一个中间位置，但是它 ~intermediateFBO~ 又是怎么绘制到 ~GL_FRAMEBUFFER~ 的默认位置 ~0~ 处的呢？（ ~glBindFramebuffer(GL_FRAMEBUFFER, 0);~ 绑定到默认帧缓冲 ~0~ 处）

这是 ~离屏 MSAA~ 的最终效果（可以和上图比较一下抗锯齿效果）：

#+ATTR_HTML: :width 80%
[[file:files/20241012_0.png]]

补充一下上一小段中提到的这个 ~intermediateFBO~ ，其实它是本节内容中最后部分中描述的要在帧缓冲中实现后期制作效果引入的内容，但是代码我却抄早了。要不然怎么设置应该显示为绿色的立方体显示成了灰色呢！

* <2024-10-12 周六> 高级光照.高级光照. ~Blinn-Phong~

按 ~B~ 键来回切换 ~Phong~ 和 ~Blinn-Phong~ 过程中有两块黑色区域一闪而过，不知道这正常不？

#+ATTR_HTML: :width 50%
[[file:files/20241012_1.gif]]

* <2024-10-12 周六> 高级光照. ~Gamma~ 校正

盗个图，来讲讲我理解的 ~gamma~ 校正

#+ATTR_HTML: :width 40%
[[file:files/gamma_correction_gamma_curves.png]]

+ 颜色用浮点数表示在 ~0.0-1.0~ 之间。
  - 颜色的 ~1/2.2~ 次方（幂）是凸形的暗红色虚线。
  - 颜色的 ~2.2~ 次方（幂）是凹形的暗红色实线。
  - 直虚线表示人眼看到的真实的物理世界。
+ 由于显示器的物理属性偏暗，即小于 ~1~ 的数的 ~2.2~ 次方（幂）的值比 ~1~ 小。
  - 如果没有 ~gamma~ 校正，期望显示效果是直虚线，而实际显示器显示出来的却是暗红色实线，偏暗。
  - 如果有了 ~gamma~ 校正，校正后的是暗红色虚线，这样经过显示器显示后的就是直虚线，显示正常。
+ 所以 ~gamma~ 校正就是将颜色变成 ~1/2.2~ （即 ~0.45~ ）次方（幂），将其变亮。

对 ~sRGB~ 目前没有概念，只知道 ~sRGB~ 空间中存放的是 ~gamma~ 校正后的颜色，这样就引出 ~OpenGL~ 中的 ~sRGB纹理~ 的概念：即当你面对着显示器制作纹理时，这个纹理肯定是在 ~sRGB~ 空间中的，这样很直观，这样制作并保存的纹理就是 ~gamma~ 校正过的，当这个纹理提供给别人使用时，可能再被 ~gamma~ 校正一次，这样就变成了两次 ~gamma~ 校正了，这样效果更亮，就不是所期望的效果了，所以需要重校， ~OpenGL~ 提供了方案来解决这个麻烦，这就是 ~GL_SRGB~ 和 ~GL_SRGB_ALPHA~ 内部纹理格式。

* <2024-10-12 周六> 高级光照.阴影映射（一）

正式开始学习 ~阴影映射~ ，基于深度测试的代码进行修改，换成了 ~wood.png~ 的皮肤，所以初始状态是这样的：

#+ATTR_HTML: :width 50%
[[file:files/20241012_2.png]]

* <2024-10-13 周日> 复习

还需要从头再回看一次，由于进度太快，前面学得忘了，这里阴影映射部分已经进行不下去了！

** 第一章，《你好，三角形》

#+begin_quote
标准化设备坐标（ ~Normalized Device Coordinates, NDC~ ）

一旦你的顶点坐标已经在顶点着色器中处理过，它们就应该是 *标准化设备坐标* 了。
#+end_quote

这就是 ~NDC~ 坐标系，因为 ~opengl~ 的坐标范围是 ~-1.0~ 至 ~1.0~ ：

#+ATTR_HTML: :width 50%
[[file:files/ndc.png]]

#+begin_quote
线框模式（ ~Wireframe Mode~ ）

要想用线框模式绘制你的三角形，你可以通过 ~glPolygonMode(GL_FRONT_AND_BACK, GL_LINE)~ 函数配置 ~OpenGL~ 如何绘制图元。第一个参数表示我们打算将其应用到所有的三角形的正面和背面，第二个参数告诉我们用线来绘制。之后的绘制调用会一直以线框模式绘制三角形，直到我们用 ~glPolygonMode(GL_FRONT_AND_BACK, GL_FILL)~ 将其设置回默认模式。
#+end_quote

之所以这里要引用过来，是因为在几何着色器那节，我只绘制出四个实体颜色小房子，却没有像书中那样绘制效果其中有两个小房子是线框而没有颜色。

** 第一章，《着色器》

#+begin_quote
片段插值（ ~Fragment Interpolation~ ），当渲染一个三角形时，光栅化（ ~Rasterization~ ）阶段通常会造成比原指定顶点更多的片段。光栅会根据每个片段在三角形形状上所处相对位置决定这些片段的位置。基于这些位置，它会插值（ ~Interpolate~ ）所有片段着色器的输入变量。
#+end_quote

因为我隐约感觉在哪里看过，所以这次复习是有意义的，这里就回答了我在[[白色屋顶][白色屋顶]]中的疑问。因为同样的道理你想啊，你只提供了三个顶点，为什么能绘制出一个三角形，在三角形边上的任意一点坐标你也没有提供，但 ~opengl~ 就是绘制出来了，所以虽然你只提供了三个顶点的颜色值，最后却是生成了一个大调色板。

关于 ~uniform~ ，在代码中设置该类型变量，先通过 ~glGetUniformLocation~ 获得 *位置值* ，然后用 ~glUniform~ 设置该 *位置值* 的变量的值。

** 第一章，《纹理》

这节中的《纹理单元》小节，没学扎实，居然没有理解 ~纹理单元~ 的概念，也没有注意到片断着色器中的 ~sampler2D~ 的 ~uniform~ 变量居然在代码中没有为它设置值，那么程序又是如何正确显示纹理的呢？

前提要清楚最终绘制纹理的过程应该是：

_顶点着色器中的是纹理坐标，但是没有纹理像素值，所以片断着色器必须要能访问纹理像素值。_

1. 先激活纹理单元，就是 ~uniform~ 的 *位置值* 。
2. 再绑定纹理单元给采样器。
3. 最后调用 ~glDrawElements~ 绘制出纹理。

即：

#+begin_src c++
  glActiveTexture(GL_TEXTURE0); // 在绑定纹理之前先激活纹理单元
  glBindTexture(GL_TEXTURE_2D, texture);
#+end_src

先 *回想上节讲的 ~uniform~ 变量的位置值* ，再看书中所说的：

#+begin_quote
你可能会奇怪为什么 ~sampler2D~ 变量是个 ~uniform~ ，我们却不用 ~glUniform~ 给它赋值。使用 ~glUniform1i~ ，我们可以给纹理采样器分配一个位置值，这样的话我们能够在一个片段着色器中设置多个纹理。一个 *纹理的位置值* 通常称为一个 *纹理单元（ ~Texture Unit~ ）* 。一个纹理的默认纹理单元是 ~0~ ，它是默认的激活纹理单元，所以教程前面部分我们没有分配一个位置值。
#+end_quote

那么现在第一步满足了，因为本例中只使用了一个纹理，默认的纹理单元 ~0~ 又是默认激活的（纹理单元 ~GL_TEXTURE0~ 默认总是被激活），再看本例代码中：

#+begin_src c++
  // bind Texture
  glBindTexture(GL_TEXTURE_2D, texture);
#+end_src

那么现在第二步也满足了，将纹理单元 ~0~ 绑定给采样器 ~sampler2D~ 了，最后：

#+begin_src c++
  // render container
  ourShader.use();
  glBindVertexArray(VAO);
  glDrawElements(GL_TRIANGLES, 6, GL_UNSIGNED_INT, 0);
#+end_src

这时三个条件都满足了，所以本例代码中的纹理虽然没有调用 ~glUniform~ 给采样器 ~sampler2D~ 赋值，但是却正确显示出来了。

** 第一章，《变换》

这里全是数学知识，向量的，矩阵的，其中有几个图特别得重要，在此盗一下：

1. 缩放：

#+ATTR_HTML: :width 30%
[[file:files/20241013_0.png]]

2. 位移：

#+ATTR_HTML: :width 30%
[[file:files/20241013_1.png]]

*注意如果乘数那个向量的齐次坐标 ~1~ 改为 ~0~ 的话，那么乘法结果都加的是 ~0~ ，导致位移失效，所以齐次坐标为 ~0~ 的坐标就是方向向量（ ~Direction Vector~ ）。*

3. 先缩放 ~2~ 倍，然后位移 ~(1, 2, 3)~ 个单位：

#+ATTR_HTML: :width 30%
[[file:files/20241013_2.png]]

最后一个例子注意（虽然我没亲手尝试）：

#+begin_src c++
  glm::mat4 trans;
  trans = glm::translate(trans, glm::vec3(0.5f, -0.5f, 0.0f));
  trans = glm::rotate(trans, (float)glfwGetTime(), glm::vec3(0.0f, 0.0f, 1.0f));
#+end_src

#+begin_quote
记住，实际的变换顺序应该与阅读顺序相反：尽管在代码中我们先位移再旋转，实际的变换却是先应用旋转再是位移的。
#+end_quote

** 第一章，《坐标系统》

这里的概念很重要，它明确了顶点着色器输出的数据是啥样的：

#+begin_quote
~OpenGL~ 希望在每次顶点着色器运行后，我们可见的所有顶点都为标准化设备坐标（ ~Normalized Device Coordinate, NDC~ ）。也就是说，每个顶点的 ~x~ ， ~y~ ， ~z~ 坐标都应该在 ~-1.0~ 到 ~1.0~ 之间，超出这个坐标范围的顶点都将不可见。我们通常会自己设定一个坐标的范围，之后再在顶点着色器中将这些坐标变换为标准化设备坐标。然后将这些标准化设备坐标传入光栅器（ ~Rasterizer~ ），将它们变换为屏幕上的二维坐标或像素。
#+end_quote

三个矩阵分别是什么用途？

1. 局部空间（顶点数据）至世界空间通过模型矩阵（ ~Model Matrix~ ）
2. 将世界坐标变换到观察空间通过观察矩阵（ ~View Matrix~ ）
3. 为了将顶点坐标从观察变换到裁剪空间，需要定义一个投影矩阵（ ~Projection Matrix~ ）

原来， *透视除法是在每一个顶点着色器运行的最后被自动执行的* ，见：

#+begin_quote
透视除法（ ~Perspective Division~ ）将会执行，在这个过程中我们将位置向量的 ~x~ ， ~y~ ， ~z~ 分量分别除以向量的齐次 ~w~ 分量；透视除法是将 ~4D~ 裁剪空间坐标变换为 ~3D~ 标准化设备坐标的过程。 *这一步会在每一个顶点着色器运行的最后被自动执行。*
#+end_quote

这里也很重要：

#+begin_quote
顶点着色器的输出要求所有的顶点都在裁剪空间内，这正是我们刚才使用变换矩阵所做的。 ~OpenGL~ 然后对 *裁剪坐标* 执行 *透视除法* 从而将它们变换到 *标准化设备坐标* 。 ~OpenGL~ 会使用 ~glViewPort~ 内部的参数来将标准化设备坐标映射到 *屏幕坐标* ，每个坐标都关联了一个屏幕上的点（在我们的例子中是一个 ~800x600~ 的屏幕）。这个过程称为视口变换。
#+end_quote

因此我整理的整个坐标变换流程如下：

1. *局部坐标* 通过 *模型矩阵* 转化为 *世界坐标* 。
2. *世界坐标* 通过 *观察矩阵* 转化为 *观察坐标* 。
3. *观察坐标* 通过 *投影矩阵* 转化为 *裁剪坐标* 。
4. *裁剪坐标* 通过 *透视除法* 转化为 *标准化设备坐标* 。
5. *标准化设备坐标* 使用 ~glViewPort~ 内部的参数转化为 *屏幕坐标* 。

关于模型矩阵书中那个例子值得提一下：

#+begin_quote
你可以将它（模型矩阵）想像为变换一个房子，你需要先将它缩小（它在局部空间中太大了），并将其位移至郊区的一个小镇，然后在 ~y~ 轴上往左旋转一点以搭配附近的房子。
#+end_quote

右手坐标系：

#+ATTR_HTML: :width 30%
[[file:files/coordinate_systems_right_handed.png]]

** 第一章，《摄像机》

这次回来再看 ~摄像机方向~ 就理解了，即：对于摄像机（观察空间）来说，需要四个变量：

1. 摄像机所在的位置
2. 摄像机观察的方向，即 ~z~ 轴负方向
3. 一个指向它右侧的向量，即 ~x~ 轴正方向
4. 一个指向它上方的向量，即 ~y~ 轴正方向

关于摄影机观察的方向，引用：

#+begin_quote
现在我们让摄像机指向场景原点： ~(0, 0, 0)~ 。还记得如果将两个矢量相减，我们就能得到这两个矢量的差吗？用场景原点向量减去摄像机位置向量的结果就是摄像机的指向向量。由于我们知道摄像机指向 ~z~ 轴负方向，但我们希望方向向量（ ~Direction Vector~ ）指向摄像机的 ~z~ 轴正方向。
#+end_quote

#+begin_src c++
  glm::vec3 cameraTarget = glm::vec3(0.0f, 0.0f, 0.0f);
  glm::vec3 cameraDirection = glm::normalize(cameraPos - cameraTarget);
#+end_src

从上面引用的话理解就是：

1. 拿原点 ~cameraTarget~ 减去摄像机位置 ~cameraPos~ 得到的方向向量是，即从摄像机指向原点，也就是局部坐标系的 ~z~ 负方向。
2. 因为希望在摄像机的坐标系中跟局部坐标系保持一致，也是屏幕指向我的方向是正方向，所以上面代码中使用了 ~()cameraPos - cameraTarget)~ 来反射的 ~z~ 的方向。

即摄像机的坐标系最终成为下图的最右侧的样子：

#+ATTR_HTML: :width 60%
[[file:files/camera_axes.png]]

理解了上面的四个变量，这个 ~LookAt矩阵~ 就非常好理解了：

#+begin_src c++
  glm::mat4 view;
  view = glm::lookAt(glm::vec3(0.0f, 0.0f, 3.0f),
                     glm::vec3(0.0f, 0.0f, 0.0f),
                     glm::vec3(0.0f, 1.0f, 0.0f));
#+end_src

1. 三个参数分别表示：
   + 摄像机的位置向量
   + 被观察的目标向量
   + 摄像机的向上向量
2. 有了这三个参数，就能计算出一个摄像机的坐标系，通过叉乘。

* <2024-10-14 周一> 高级光照.阴影映射（二）

#+begin_src c++
  glDrawBuffer(GL_NONE);
  glReadBuffer(GL_NONE);
#+end_src

文中这两行代码表示：
#+begin_quote
告诉 ~OpenGL~ 我们不适用任何颜色数据进行渲染。我们通过将调用 ~glDrawBuffer~ 和 ~glReadBuffer~ 把读和绘制缓冲设置为 ~GL_NONE~ 来做这件事。
#+end_quote

因为没有颜色缓冲对于帧缓冲是不完整的，在后面进行完整性测试时会失败，所以这里是必需的。

#+begin_src c++
  if (glCheckFramebufferStatus(GL_FRAMEBUFFER) != GL_FRAMEBUFFER_COMPLETE) {
    std::cout << "ERROR::FRAMEBUFFER:: Framebuffer is not complete!" << std::endl;
   }
#+end_src

** 深度贴图

关于深度贴图（ ~Depth Map~ ）流程如下：

1. 创建一个帧缓冲对象，创建一个 ~2D~ 深度纹理，并把生成的深度纹理作为帧缓冲的深度缓冲。
2. 首先渲染至深度贴图。
   + 这里就需要以光源的视角了，所以就需要在顶点着色器中将顶点变换到光源。
   + 这里使用了 ~正交投影矩阵~ 和 ~lookat矩阵~ 。
3. 最后像往常一样渲染场景，但这次使用的是深度贴图。

我得到了和书中相同的深度贴图：

#+ATTR_HTML: :width 50%
[[file:files/20241014_0.png]]

备注：顶点着色器和片断着色器的文件名从 ~5.2~ 改为 ~5.3~ ，因为 ~5.2~ 节讲的是 ~gamma~ 校正。

** 渲染阴影

关于渲染阴影的步骤（在生成深度贴图的基础上）：

1. 在顶点着色器中要输出两个变量，后一个变量用于片断着色器中计算阴影。
   1) ~FragPos~ 变量，它表示普通的经变换的世界空间顶点位置（在 ~blinn phong~ 已经见过，不是新内容）。
   2) ~FragPosLightSpace~ 变量，它表示普通世界空间顶点变换后的光空间中顶点位置。
2. 在片断着色器中计算阴影。
   1) 对 ~FragPosLightSpace~ 做透视除法，因为它不是通过 ~gl_Position~ 传入的，所以要自己做。
   2) 计算得的分量在 ~[-1, 1]~ 之间，转化为 ~[0, 1]~ 之间以匹配深度贴图中的深度值。
   3) 计算光的位置视野下最近的深度：
      + ~float closestDepth = texture(shadowMap, projCoords.xy).r;~
   4) 获得片断当前深度，与最近深度一比较即可得到是否在阴影下。

问题： ~texture(shadowMap, projCoords.xy).r~ 不记得书中有交待过 ~texture(...).r~ 可以获得深度值呀！

最终代码效果如下：

#+ATTR_HTML: :width 50%
[[file:files/20241014_1.png]]

** 阴影失真（ ~Shadow Acne~ ）

阴影失真理解起来不太形象，我好奇成因当初是怎么分析出来的？因为 *地板以下* 采样的会出现黑色，所以通过：

#+begin_quote
一个叫做阴影偏移（ ~shadow bias~ ）的技巧来解决这个问题，我们简单的对表面的深度（或深度贴图）应用一个偏移量，这样片段就不会被错误地认为在表面之下了。
#+end_quote

#+ATTR_HTML: :width 50%
[[file:files/shadow_mapping_acne_diagram.png]]

#+ATTR_HTML: :width 50%
[[file:files/shadow_mapping_acne_bias.png]]

** PCF（ ~percentage-closer filtering~ ）

#+begin_quote
PCF（ ~percentage-closer filtering~ ），这是一种多个不同过滤方式的组合，它产生柔和阴影，使它们出现更少的锯齿块和硬边。核心思想是从深度贴图中多次采样，每一次采样的纹理坐标都稍有不同。每个独立的样本可能在也可能不再阴影中。所有的次生结果接着结合在一起，进行平均化，我们就得到了柔和阴影。
#+end_quote

感觉东西越学越多，又出来一个 ~textureSize~ 的 ~opengl~ 函数，它返回一个给定采样器纹理的 ~0~ 级 ~mipmap~ 的 ~vec2~ 类型的宽和高。（这是啥意思？）

回忆：书中讲到的 ~mipmap~ 是在《纹理》那一节中：

#+begin_quote
~OpenGL~ 使用一种叫做多级渐远纹理（ ~Mipmap~ ）的概念来解决这个问题，它简单来说就是一系列的纹理图像，后一个纹理图像是前一个的二分之一。
#+end_quote

这里 ~PCF~ 的意思是通过 ~mipmap~ 搞个偏移量，确保每个新样本来自不同的深度值。

* <2024-10-15 周二> 高级光照.阴影映射（三）

** 点光源阴影（也叫万向阴影贴图 ~omnidirectional shadow maps~ ）

他也分为两个渲染阶段：

1. 首先我们生成深度贴图。
   1) 深度贴图使用的是立方体贴图，它是在 *几何* 着色器中生成的。
   2) 渲染深度立方体贴图时： *几何* 着色器是负责将所有世界空间的顶点变换到 ~6~ 个不同的光空间的着色器。因此 *顶点* 着色器简单地将顶点变换到世界空间（即只乘以 ~模型矩阵~ ），然后直接发送到 *几何* 着色器。
   3) 几何着色器中处理投影和视图矩阵，即将顶点变换到光空间中。
   4) 几何着色器中处理的为什么是 ~6~ 个三角形，共 ~18~ 个点？我的理解是 ~24~ 个呀。
   5) 片段着色器中自己计算深度值（而上节用的是空的片段着色器，是让 ~opengl~ 配置深度贴图的深度值）。
2. 然后使用深度贴图渲染，在场景中创建阴影。

#+begin_src c++
  glm::lookAt(lightPos, lightPos + glm::vec3(1.0f, 0.0f, 0.0f), glm::vec3(0.0f, -1.0f, 0.0f))
#+end_src

这句代码的意思是：

+ 第二个参数表示目标位置是 ~lightPos + glm::vec3(1.0f, 0.0f, 0.0f)~ 即向右看，因为第一个分量是 ~1.0~ 。
+ 第三个参数表示向上的向量 ~glm::vec3(0.0f, -1.0f, 0.0f)~ 是说明 ~y~ 轴的负方向（为什么不是 ~1.0~ 正方向？）

有几个要尝试的地方：

1. 更换顶点顺序看面剔除表现。
2. 上小段中 ~y~ 轴改为正方向的绘制效果。
   1) 修改成 ~1.0~ 后绘制效果是错误的。
   2) 终于想通为什么是 ~-1.0~ 了：
      + ~lightPos~ 虽然是光源位置，这里就是理解中的摄像机位置，因为光源不可能是被观察对象，要不然怎么观察阴影效果呢？所以光源才是摄像机的位置。
      + 那么被观察对象就是 ~lightPos + glm::vec3(1.0f, 0.0f, 0.0f)~ ，即向右的方向。
      + 想像自己正在向右看，观察方向是从自己指向屏幕，中指对应 ~z~ 轴正方向，指向屏幕，大拇指表示 ~x~ 轴指向右，则食指朝下，所以第三个参数就是 ~glm::vec3(0.0f, -1.0f, 0.0f)~ 。
      + 而在《摄像机》那节，从提供的图可以看出，摄像机坐标系的 ~z~ 轴正向是从屏幕指向自己的，所以这里的情况与它是相反的。
3. 我对 ~ShadowCalculation~ 函数中向量减法顺序的疑问。
   1) 经尝试也不能颠倒他们的顺序，绘制效果是错误的。
   2) *但是目前尚无法理解* 。
